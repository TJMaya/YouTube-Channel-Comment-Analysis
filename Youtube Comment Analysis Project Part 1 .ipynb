{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Comment Analysis Project Part 1: Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we grab the url of the youtube channel for whom we want to srape info from, create the driver object to navigate the site, and have the driver open via the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!Enter the channel that you want to scrape inbetween c and videos\n",
    "#!!!!!!!!Remember you need to have a chromedriver installed\n",
    "url = 'https://www.youtube.com/c//videos'\n",
    "driver = webdriver.Chrome('C:/bin/chromedriver.exe')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then create a function that will have the driver scroll to the bottom of whatever page is currently open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_bottom():\n",
    "    #Instructs the driver to scroll to the bottom of the page and returns the end scrollHeight\n",
    "    pageLength = driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);return document.documentElement.scrollHeight;\")\n",
    "    end = False\n",
    "\n",
    "    #Loops the above exec until the page can't scroll any further\n",
    "    while(end==False):\n",
    "        lastLength = pageLength\n",
    "        time.sleep(3)\n",
    "        pageLength = driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);return document.documentElement.scrollHeight;\")\n",
    "        if lastLength==pageLength:\n",
    "            end=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This block of code will auto scroll to the bottom of the videos page of a YouTube channel and then proceed to scrape each video's mos basic data which includes its title, link, and number of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create some lists to hold all of the basic video info from the youtube channel\n",
    "title = []\n",
    "link = []\n",
    "views = []\n",
    "   \n",
    "scroll_bottom()\n",
    "\n",
    "#Create a videos list that holds all of the video elements that hold the basic info such as title, link, and views\n",
    "videos = driver.find_elements_by_class_name('style-scope ytd-grid-video-renderer')\n",
    "\n",
    "#!!!!!!!!We're only scraping 155 of the most recent videos\n",
    "#!!!!!!!!You can replace 155 with any number of videos you want to scrape\n",
    "del videos[155:]\n",
    "\n",
    "#Loop through each video element, retrieve each video's basic info and append it to the prepared lists title, link, and views\n",
    "for video in videos:\n",
    "    v_title = video.find_element_by_xpath('.//*[@id=\"video-title\"]').text\n",
    "    v_link = video.find_element_by_xpath('.//*[@id=\"video-title\"]').get_attribute('href')\n",
    "    v_views = video.find_element_by_xpath('.//*[@id=\"metadata-line\"]/span[1]').text\n",
    "    title.append(v_title)\n",
    "    link.append(v_link)\n",
    "    views.append(v_views)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This block of code will loop through each video page and each comment to retrieve the post date, likes, dislikes, comment author, comment text, and comment likes.\n",
    "### It will then create dictionary items that hold of the info and append them to a final list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list to hold each individual comment along with all relevant video data.\n",
    "#Each entry will be a dictionary item that will hold title, link, views, date, likes, dislikes, author, comment text, and comment likes.\n",
    "comment_list = []\n",
    "\n",
    "#Loop through each video link, and scrape all relevant data, and appending it to comment_list\n",
    "for v_link in range(len(link)):\n",
    "    \n",
    "    #Create a new driver session each loop to avoid failures to load url that often occurs during continuous sessions\n",
    "    driver.quit()\n",
    "    driver = webdriver.Chrome('C:/bin/chromedriver.exe')\n",
    "    driver.get(link[v_link])\n",
    "    \n",
    "    time.sleep(3) #Give link time to load\n",
    "    \n",
    "    ###In case you need to play/pause video at start\n",
    "    #button = driver.find_element_by_xpath('.//*[@id=\"movie_player\"]')\n",
    "    #button.click()\n",
    "    \n",
    "    scroll_bottom() #Scroll to bottom to make sure every comment is loaded in\n",
    "    \n",
    "    #Video_info will be the element that will hold more the video's basic info\n",
    "    video_info = driver.find_element_by_class_name('style-scope ytd-video-primary-info-renderer')\n",
    "    \n",
    "    #Retrieve the video's post date, likes, and dislikes\n",
    "    video_date = video_info.find_element_by_xpath('.//*[@id=\"date\"]/yt-formatted-string').text\n",
    "    video_likes = video_info.find_elements_by_xpath('.//*[@id=\"text\"]')[0].text\n",
    "    video_dislikes = video_info.find_elements_by_xpath('.//*[@id=\"text\"]')[1].text\n",
    "\n",
    "    #Comments list will hold all instances of a comment and the info relevant to it\n",
    "    comments = driver.find_elements_by_class_name('style-scope ytd-comment-renderer')\n",
    "    \n",
    "    #Loop through each comment element and extract the author, comment text, and comment likes\n",
    "    for comment in comments:\n",
    "        v_author = comment.find_element_by_xpath('.//*[@id=\"author-text\"]/span').text\n",
    "        v_comment = comment.find_element_by_xpath('.//*[@id=\"content-text\"]').text\n",
    "        v_likes = comment.find_element_by_xpath('.//*[@id=\"vote-count-middle\"]').text\n",
    "       \n",
    "        #Create a dictionary item to append all the video information to the comment_list\n",
    "        comment_item = {\n",
    "        'title': title[v_link],\n",
    "        'link': link[v_link],\n",
    "        'views': views[v_link],    \n",
    "        'date': video_date,\n",
    "        'likes': video_likes,  \n",
    "        'dislikes': video_dislikes,   \n",
    "        'author': v_author,\n",
    "        'comment_text': v_comment,\n",
    "        'comment_likes': v_likes\n",
    "        }\n",
    "        comment_list.append(comment_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we convert the final comment list into a pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6fd7362b5498>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomment_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcomment_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "comment_df = pd.DataFrame(comment_list)\n",
    "comment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Finally export this info for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df.to_csv(\"comment_info.csv\", index = False, header = True)\n",
    "comment_df.to_excel(\"comment_info.xlsx\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
